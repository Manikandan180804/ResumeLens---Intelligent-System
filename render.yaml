services:
  - type: web
    name: resumelens-api
    runtime: python
    # Use --index-url FIRST so pip resolves torch to CPU-only wheels (not CUDA)
    # The +cpu suffix in requirements.txt enforces this at the package level too
    buildCommand: pip install --upgrade pip && pip install --index-url https://download.pytorch.org/whl/cpu --extra-index-url https://pypi.org/simple/ -r requirements.txt
    startCommand: uvicorn backend.main:app --host 0.0.0.0 --port $PORT
    plan: free
    envVars:
      - key: PYTHON_VERSION
        value: 3.11.0
      - key: LLM_PROVIDER
        value: groq
      - key: LLM_MODEL
        value: llama-3.3-70b-versatile
      - key: USE_LOCAL_LLM
        value: "false"
      - key: GROQ_API_KEY
        sync: false          # set manually in Render Dashboard â†’ Environment
      - key: DATABASE_URL
        value: sqlite:////tmp/resume_intelligence.db
      - key: VECTOR_DB_TYPE
        value: faiss
      - key: EMBEDDING_MODEL
        value: sentence-transformers/all-MiniLM-L6-v2
      - key: DEBUG
        value: "false"
